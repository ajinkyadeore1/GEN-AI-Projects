# Gemini LLM Chatbot

## Overview

This project is a chatbot application that leverages Google's Gemini Pro model to provide intelligent responses to user queries. Built with Streamlit, it offers an interactive and user-friendly interface for real-time conversation.

## Use Case

The chatbot is designed for:

- Answering general knowledge questions
- Providing AI-generated insights based on input
- Experimenting with Generative AI capabilities
- Enhancing AI-powered conversational experiences

## Features

- **Streamlit UI**: A simple and interactive frontend for user queries.
- **Google Gemini Pro API**: Integration with the Gemini LLM for intelligent responses.
- **Chat History**: Saves user queries and responses in a JSON file.
- **Session Management**: Maintains chat history during the session.
- **Clear Chat Option**: Users can reset their chat history anytime.

## Tools & Technologies Used

- **Python**: The core programming language.
- **Streamlit**: For creating the web-based user interface.
- **Google Generative AI SDK**: To access Gemini Pro capabilities.
- **dotenv**: For managing API keys securely.
- **JSON**: For storing and managing chat history.


 #Run the application:
   ```bash
   streamlit run app.py
   ```

## Usage

1. Enter a question in the input field.
2. Click the "Submit" button to get a response from the Gemini LLM.
3. View the conversation history and clear it if needed.

## Contribution

Contributions are welcome! Feel free to fork the repository and submit pull requests.




